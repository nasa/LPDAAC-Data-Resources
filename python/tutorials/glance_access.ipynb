{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7206671-44e8-434d-9afd-b980afc511b8",
   "metadata": {},
   "source": [
    "# Getting Started with Global Land Cover Mapping and Estimation Yearly 30 meter (GLanCE30)\n",
    "\n",
    "## Summary  \n",
    "\n",
    "This tutorial was developed to examine changes in Land Cover surrounding the [Waubay National Wildlife Refuge](https://www.fws.gov/refuge/waubay) in northeast South Dakota (USA). **The goal of the project is to demonstrate a practical use case of using GLanCE30 to observe Land Cover change in this area over time without downloading the GLanCE30 source data.** In this notebook we will show an Land Cover timeseries from GLanCE30 data in the Cloud using the `earthaccess` and `rioxarray` libraries. This tutorial will show how to find the GLanCE30 data available in the cloud for our specific time period, bands (layers), and region of interest. After finding the desired data, we will load subsets of the cloud optimized geotiffs (COGs) into a Jupyter Notebook directly from the cloud, and show Land Cover change in tabular, quantitative visualization and map chart formats.\n",
    "\n",
    "## Background  \n",
    "\n",
    "NASA’s Making Earth System Data Records for Use in Research Environments ([MEaSUREs](https://earthdata.nasa.gov/about/competitive-programs/measures?_gl=1*xc5qp5*_ga*OTg2MDk1NDkuMTc0Njc5NjQ1MQ..*_ga_0YWDZEJ295*czE3NDcxNTgxMTYkbzQkZzEkdDE3NDcxNjAxNTYkajAkbDAkaDA.)) Global Land Cover Mapping and Estimation Yearly 30 meter ([GLanCE30](https://doi.org/10.5067/MEaSUREs/GLanCE/GLanCE30.001)) project produces an annual 30 meter global land cover and land cover change data product derived from the Landsat 5 Thematic Mapper (TM), Landsat 7 Enhanced Thematic Mapper Plus (ETM+), and Landsat 8 Operational Land Imager (OLI). GLAnce science data layers are designed to describe two landscape attributes:\n",
    "\n",
    "1.\tLand Cover and Land Cover Change. Four SDSs provide information related to: (1) the land cover class; (2) the estimated quality associated with the land cover class1; (3) the previous land cover class for those pixels where change occured; and (4) the approximate day of year (DOY) of change.\n",
    "2.\tMagnitude, Seasonality, and Changes in Greenness. Four SDSs are included that characterize annual greenness at each pixel via the Enhanced Vegetation Index (EVI2): (1) median; (2) amplitude; (3) rate of change (if present); and (4) magnitude of change in EVI2 median for those pixels where change occurred.\n",
    "\n",
    "GLanCE products are useful for a variety of applications including monitoring the response of terrestrial ecosystems and land management. \n",
    "\n",
    "NASA's Land Processes Distributed Active Archive Center (LP DAAC) archives and distributes GLanCE30 products in the LP DAAC Cumulus cloud archive as Cloud Optimized GeoTIFFs (COG). This tutorial will demonstrate because these data are stored as COGs, this tutorial will teach users how to load subsets of individual files into memory for just the layers you are interested in. This tutorial covers how to search for, process and \"stack\" the GLanCE30 data over a region of interest into an [xarray](http://xarray.pydata.org/en/stable/) data array filter and visualize land cover and land change over the time series. \n",
    "\n",
    "## Requirements  \n",
    "\n",
    "- A [NASA Earthdata Login](https://urs.earthdata.nasa.gov/) account is required to download the data used in this tutorial. You can create an account at the link provided.\n",
    "\n",
    "- A compatible Python environment with the VSWIR Imaging and Thermal Applications, Learning, and Science ([VITALS](https://github.com/nasa/VITALS/tree/main)) environment installed. Please refer to the [Setup](https://github.com/nasa/VITALS/blob/main/setup/setup_instructions.md) Instructions for setting up the VITALS Environment.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "- How to work with GLanCE30 ([GLANCE30v001](https://doi.org/10.5067/MEaSUREs/GLanCE/GLanCE30.001)) data products  \n",
    "- How to query and GLanCE30 HLS data using the earthaccess library  \n",
    "- How to access and work with GLanCE30 data\n",
    "\n",
    "## Data Used  \n",
    "\n",
    "Annual 30 meter (m) Global Land Cover Mapping and Estimation Yearly 30 m - [glance30v001](https://doi.org/10.5067/MEaSUREs/GLanCE/GLanCE30.001)\n",
    " - Science Dataset (SDS) layers:  \n",
    "        - LC (Integer identifier for class in the current year)  \n",
    "        - PrevClass\t(Integer identifier for class in previous year, if change has occurred; N/A if no change)\n",
    " - The SDS Layers in this tutorial utilize a seven class integer system to identify land cover. The table below denotes the class number and its corresponding description.\n",
    "\n",
    "|Value    |           Name               | Description  |\n",
    "| :----:  |          :----:              | :---       |\n",
    "| 1       |           Water              | Areas covered with water throughout the year: streams, canals, lakes, reservoirs, and oceans.      |\n",
    "| 2       |          Ice/Snow            | Land areas where snow and ice cover is greater than 50% throughout the year.       |\n",
    "| 3       |          Developed           | Areas of intensive use; land covered with structures, including any land functionally related to          developed/built-up activity.             |\n",
    "| 4       | Barren/Sparsely Vegetated    | Land consists of natural occurrences of soils, sand, or rocks where less than 10% of the area is vegetated.       |\n",
    "| 5       |          Tree Cover          | Land where the tree cover is greater than 30%. Note that cleared trees (i.e., clear-cuts) are mapped according to current cover (e.g., barren/sparsely vegetated, shrubs, or grasses).       |\n",
    "| 6       |          Shrublands          |Land with less than 30% tree cover, where total vegetation cover exceeds 10% and shrub cover is greater than 10%.       |\n",
    "| 7       |          Herbaceous          | Land covered by herbaceous cover. Total vegetation cover exceeds 10%, tree cover is less than 30%, and shrubs comprise less than 10% of the area.      |\n",
    "\n",
    "## Tutorial Outline  \n",
    "\n",
    "1. [**Getting Started**](#getstarted)  \n",
    "    1.1 Import Packages<br>\n",
    "    1.2 Setup Current Working Directory  \n",
    "    1.3 EarthData Login  \n",
    "2. [**Finding GLanCE30 Data**](#find)<br>\n",
    "    2.1 Set spatial and temporal search parameters<br>\n",
    "    2.2 Visualize where the spatial location is we are working with<br>\n",
    "    2.3 Perform Data Query for GLanCE30 data within our geographic and temporal periods of interest and review the results   \n",
    "3. [**Accessing GLanCE30 COG Data in the Cloud**](#cloudaccess)  \n",
    "    3.1 Group by Band\n",
    "4. [**Processing GLanCE30 Data**](#processglance)   \n",
    "    4.1 Load GLanCE30 data into memory and subset spatially  \n",
    "    4.2 Make all 36 subset SDS Layers into one xarray dataset \n",
    "    4.3 Export to COG  \n",
    "5. [**Visualizations of GLanCE30 Data**](#Visualizations)\n",
    "    5.1 Visualize Land Cover from the GLanCE30 Land Cover Time Series<br>\n",
    "    5.2 Visualize Quantitative Land Cover for the Time Series in Line Chart Format<br>\n",
    "    5.3 Visualize Quantitative Previous Class Time Series in Line Chart Format<br>\n",
    "    5.4 Visualize Land Cover from the GLanCE30 Previous Class Time Series<br>\n",
    "    5.5 Visualize Land Cover from the GLanCE30 Previous Class Time Series with a referance basemap<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bcb762d-c040-4bf6-8397-6e2581c4d0de",
   "metadata": {},
   "source": [
    "## 1. Getting Started<a id=\"getstarted\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb4f28b-b2c0-4fbf-b5f0-1bfd87def4dd",
   "metadata": {},
   "source": [
    "### 1.1 Import Packages "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6498d8-96f0-4885-9c23-0e7e18e3b338",
   "metadata": {},
   "source": [
    "Import the required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fc608d-f6e9-410f-8838-1585cefe9acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gp\n",
    "from osgeo import gdal\n",
    "import xarray as xr\n",
    "import rioxarray as rxr\n",
    "import hvplot.xarray\n",
    "import earthaccess\n",
    "import holoviews as hv\n",
    "from holoviews import opts\n",
    "import folium\n",
    "from folium import Marker\n",
    "from holoviews.plotting.util import process_cmap\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e68547-810f-4e85-a352-a7af71ba8a16",
   "metadata": {},
   "source": [
    "### 1.2 Setup Current Working Directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44815d8b-e5a6-4843-8ef5-486fda5b6bbf",
   "metadata": {},
   "source": [
    "We will use a directory called data is the default working directory for the tutorial. Any required ancillary files will be read from here also any outputs downloaded will be written here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54241d95-beb7-4260-b030-064e1480026d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../../data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e377c6a6-42a9-413f-9a62-2354728740f9",
   "metadata": {},
   "source": [
    "### 1.3 Earthdata Login Authentication"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd4fb94-d7c1-43b8-b869-27910066406c",
   "metadata": {},
   "source": [
    "We will use the [earthaccess](https://github.com/nsidc/earthaccess#readme) package for authentication. `earthaccess` can either create a new local .netrc file to store credentials or validate that one exists already in you user profile. If you do not have a .netrc file, you will be prompted for your credentials and one will be created. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d5b7bd-c904-4c55-a4b3-8f88b288d0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "earthaccess.login(persist=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed3fef6-1170-40ae-94d1-85a13fb2a5af",
   "metadata": {},
   "source": [
    "## 2. Finding GLanCE30 Data using `earthaccess` <a id=\"find\"></a>\n",
    "\n",
    "To find GLanCE30 data, we will use the `earthaccess` python library to search NASA's Common Metadata Repository (CMR) for GLanCE30 data. We will use a geojson file containing our region of interest (ROI) to search for files that intersect. To do this, we will simplify it to a bounding box. Grab the bounding coordinates from the geopandas object after opening."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa1c269-8ba5-48a9-9edb-8a7f89d81377",
   "metadata": {},
   "source": [
    "### 2.1 Set spatial and temporal search parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9008c66f-fa67-4d31-aec4-1083c96c14db",
   "metadata": {},
   "source": [
    "First we will read in our geojson file using geopandas. We will use the `total_bounds` property to get the bounding box of our ROI, and add that to a python tuple, which is the expected data type for the bounding_box parameter `earthaccess` `search_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2e19b6-4521-4adf-b72f-4ebb574c91cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "field = gp.read_file('waubay_nwf.geojson')\n",
    "bbox = tuple(list(field.total_bounds))\n",
    "bbox"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbab8b95-cd76-4cc0-bd02-85b1fbeb53e1",
   "metadata": {},
   "source": [
    "When searching we can also search a specific time period of interest. Here we search from the beginning of January 2002 to the end of December 2019. GLanCE30 is an annual product where each year is specified with the data of July 1st of each year. Therefore, we would expect to have 18 GLanCE30 products in the time series.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e114a2c-d860-4ef0-8c5f-01cbdb65a52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal = (\"2002-01-01T00:00:00\", \"2019-12-31T23:59:59\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8199fd-52ce-4dd3-b779-f426326a438f",
   "metadata": {},
   "source": [
    "## 2.2 Perform query for GLanCE30 data and review results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec22034-cc30-4d21-b364-93c9cd313b04",
   "metadata": {},
   "source": [
    "Here we perform the query to CMR for GLanCE30 data that meets our specified spatial and temporal areas of interest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b225185-83b8-4161-8882-62ea3efb8468",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = earthaccess.search_data(\n",
    "    short_name=['GLanCE30'],\n",
    "    bounding_box=bbox,\n",
    "    temporal=temporal\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa169d2-d931-4712-8d69-4359612b2019",
   "metadata": {},
   "source": [
    "We can preview these results in a `pandas` `dataframe` we want to check the metadata. Note there are 18 results returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edffbbd-efd1-4687-9a06-f09356676905",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.json_normalize(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c48211-bd12-41da-8be8-f37596428ed5",
   "metadata": {},
   "source": [
    "We can also preview each individual results by selecting it from the list. This will show the data links, and a browse image. Note the seven different  SDS layers available from the GLanCE30 product. For this tutorial we will be working with the LC and PrevClass SDS Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59365546-584d-4ec6-ba11-99aaa1f81ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2bd6961-e9a4-4a7d-a7f2-2bf2488abe9c",
   "metadata": {},
   "source": [
    "We can also examine the umm metadata which is returned as a python dictionary. In our example here we will extract the spatial bounds of one GLanCE30 product and plot the bounds on a map. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e2a85f-793f-411c-992d-a0dfe25f6bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = results[0][\"umm\"]\n",
    "metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3529407c-32dd-4d1f-856e-83501d6896f0",
   "metadata": {},
   "source": [
    "Here, we are going to extract the geometry from one GLanCE30 product. Do do this we need to key the geometry of the product from umm metadata and covert it to a polygon using the `shapely` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bd79ca-5bb0-4b61-950c-23cd67977304",
   "metadata": {},
   "outputs": [],
   "source": [
    "glance_geometry = results[0]['umm']['SpatialExtent']['HorizontalSpatialDomain']['Geometry']\n",
    "glance_points = glance_geometry['GPolygons'][0]['Boundary']['Points']\n",
    "        # Create shapely geometry from polygons\n",
    "glance_polygon = Polygon([[p[\"Longitude\"], p[\"Latitude\"]] for p in glance_points])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70df4406-a51d-44c1-bcf7-c18f60b6ae7a",
   "metadata": {},
   "source": [
    "### 2.3 Visualize ROI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3855303-8e7c-4ff0-bdab-1fa3039e177d",
   "metadata": {},
   "source": [
    "We can plot the spatial location geometry on a map visualization using the `folium` library. The geometry drawn in red shows the full extent of the GLanCE30 data. The geometry drawn in blue on the map represents the final extent we are be working with in the final xarray dataset. This visualization shows the exact amount of data we will process (blue) which is much smaller than the total of extent of the GLanCE30 product (red)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87e3d5e-6089-4c6d-9748-d16e8e105aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = folium.Map([46.0732, -97.7783], zoom_start=6, width=900, height=350, tiles='OpenStreetMap')\n",
    "folium.GeoJson(field).add_to(m)\n",
    "folium.GeoJson(glance_polygon, color = 'red').add_to(m)\n",
    "m.add_child(Marker(location=[45.3676, -97.4048], popup='Waubay, South Dakota AOI', icon = folium.Icon(color = 'red')))\n",
    "folium.LatLngPopup().add_to(m)\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44249cc0-aa7e-4c25-9f54-e6c634aeafa1",
   "metadata": {},
   "source": [
    "## 3. Accessing GLanCE30 Cloud Optimized GeoTIFFs (COGs) from Earthdata Cloud <a id=\"cloudaccess\"></a>\n",
    "Now that we have a list of data URLs, we will configure `gdal` and `rioxarray` to access the cloud assets that we are interested in, and read them directly into memory without needing to download the files. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38fc6d89-d002-4127-8138-b48e65fc2d95",
   "metadata": {},
   "source": [
    "The Python libraries used to access COG files in Earthdata Cloud leverage GDAL's virtual file systems. Whether you are running this code in the Cloud or in a local workspace, GDAL configurations must be set in order to successfully access the GLanCE30 COG files. The settings below enable GDAL to send authentication information when accessing the GLanCE30 COG files in the Earthdata Cloud and also enable retrying connections in case of network issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd43504-0c54-4b65-a596-509fd3df3985",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdal.SetConfigOption('GDAL_HTTP_COOKIEFILE','~/cookies.txt')\n",
    "gdal.SetConfigOption('GDAL_HTTP_COOKIEJAR', '~/cookies.txt')\n",
    "gdal.SetConfigOption('GDAL_DISABLE_READDIR_ON_OPEN','EMPTY_DIR')\n",
    "gdal.SetConfigOption('CPL_VSIL_CURL_ALLOWED_EXTENSIONS','TIF')\n",
    "gdal.SetConfigOption('GDAL_HTTP_UNSAFESSL', 'YES')\n",
    "gdal.SetConfigOption('GDAL_HTTP_MAX_RETRY', '10')\n",
    "gdal.SetConfigOption('GDAL_HTTP_RETRY_DELAY', '0.5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e5590b-76f8-4930-90fb-f1a8e5a6f9ca",
   "metadata": {},
   "source": [
    "### 3.1 Group by Layer Type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f3b51c-330c-4e03-a235-806a427d75ca",
   "metadata": {},
   "source": [
    "Here we can see a list of all the URLs for each GLanCE30 product. Since we have 18 years in our time series and there are seven SDS layers in each year we have here 126 URLs in this list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0929a906-1da3-4cd9-a516-d862defcb286",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "glance_results_urls = [granule.data_links() for granule in results]\n",
    "glance_results_urls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d9dd38-3683-446e-8bc3-4ae5a8280688",
   "metadata": {},
   "source": [
    "Here we group the urls by the SDS Layer Type and load this into a python dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dce6e45-6795-48b6-89ac-736197794553",
   "metadata": {},
   "outputs": [],
   "source": [
    "def varname_from_url(url):\n",
    "    return url.split(\"/\")[-1].split(\".\")[0].split(\"_\")[-1]\n",
    "\n",
    "grouped_urls = defaultdict(list)\n",
    "for granule in glance_results_urls:\n",
    "    for url in granule:\n",
    "        var = varname_from_url(url)\n",
    "        grouped_urls[var].append(url)\n",
    "\n",
    "results_dict = dict(grouped_urls)\n",
    "results_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21296ba-4ea3-483f-8296-c9f89d5c0451",
   "metadata": {},
   "source": [
    "## 4. Processing GLanCE30 Data <a id=\"processglance\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52ca331-6164-4b79-8f6b-b7d3fb18eb54",
   "metadata": {},
   "source": [
    "In this section we will load the SDS Layers for LC and PrevClass from the results_dict dictionary created above by lazy loading the SDS Layers an xarray.  We will also subset each SDS layer to the geojson area of interest used to make the query for the GLanCE30. The result will be a image of the SDS layers that are clipped to the geojson area of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4977f05-ad75-4baa-a9eb-b0759e015833",
   "metadata": {},
   "source": [
    "### 4.1 Load GLanCE30 data into memory and subset spatially"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79886d08-4602-4213-8fb9-7213676e8071",
   "metadata": {},
   "source": [
    "Here we create a function to call when lazy loading the SDS Layers using `rioxarray`. The urls for the SDS Layers are stored in the results_dict created above. This function will handle adding the date of the SDS layer as a dimension to the xarray dataset a well as clipping the dataset to the geojson area of interest file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaac6da9-265e-478c-9a1e-8feaf732bf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(ds):\n",
    "    # Squeeze Band\n",
    "    ds = ds.squeeze('band', drop=True)\n",
    "    # Time Dimension\n",
    "    url = ds.encoding['source']\n",
    "    print('Loading {}'.format(url))\n",
    "    date_str = url.split('/')[-1].split('_')[1].split('A')[1]\n",
    "    date = datetime.strptime(date_str, '%Y%m%d')\n",
    "    ds = ds.assign_coords(date=date)\n",
    "    # Clip\n",
    "    field_reproj = field.to_crs(ds.rio.crs)\n",
    "    clipped = ds.rio.clip(field_reproj.geometry.values, field_reproj.crs, all_touched=True)\n",
    "    return clipped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188e3579-d4b9-48f2-b633-2b126cfd0891",
   "metadata": {},
   "source": [
    "Here we handle the loading the SDS Layers. Of the available layers we are only loading the layers we want the LC and PrevClass SDS Layers. Each SDS Layer contributes 18 products to the final xarray."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fd70b7-9552-4d6b-80df-d0577d9c8ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_lc = xr.open_mfdataset(results_dict['LC'],\n",
    "                       engine='rasterio',\n",
    "                       band_as_variable=False,\n",
    "                       combine='nested',\n",
    "                       concat_dim='date',\n",
    "                       preprocess=preprocess,\n",
    "                       coords='minimal',\n",
    "                       ).rename({\"band_data\":'LC'})\n",
    "ds_prev = xr.open_mfdataset(results_dict['PrevClass'],\n",
    "                       engine='rasterio',\n",
    "                       band_as_variable=False,\n",
    "                       combine='nested',\n",
    "                       concat_dim='date',\n",
    "                       preprocess=preprocess,\n",
    "                       coords='minimal',\n",
    "    ).rename({\"band_data\":\"PrevClass\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8619bd5a-d7c4-43e2-9e88-5717088cfa09",
   "metadata": {},
   "source": [
    "### 4.2 Make all 36 subset SDS Layers into one xarray dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4168459f-164c-48d1-b6d0-dcaaec8a5a0c",
   "metadata": {},
   "source": [
    "Here we make the one xarray dataset containing all 36 of the subset SDS Layers created above by running a concat merge command on the two datasets created above. We can also see the size of the final array and view its contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20ddff4-b8cc-44ee-a4c5-a80afc81d83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "glance_dataset = xr.merge([ds_lc,ds_prev]).load()\n",
    "print('Dataset Size (Gb): ', glance_dataset.nbytes/1e9)\n",
    "glance_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25931d2-1e47-4e4e-807e-2e881cf30896",
   "metadata": {},
   "source": [
    "## 5. Visualizations of GLanCE30 Data <a id=\"visualize\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84db846-9bac-4556-89cb-b050c7e596cb",
   "metadata": {},
   "source": [
    "In this section we will explorer different ways to gain information from the subset LC and PrevClass GLanCE30 SDS layers. This will leverage the glance_dataset xarray dataset created in section 4 with various filtering techniques. We will make a map visualizations of the Land Cover classes across the time series, show the number of pixels of each Land Cover Class as a line chart, show where land cover has changed from the previous year using the PrevClass SDS layer and show the number pixels of each class that changed from the previous year as a line chart, finally we will show a map visualization of change in the time series overlayed on a reference map. This will be done using the `holoviews` python module."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f85b75-5985-431b-8483-44df2da3c2e3",
   "metadata": {},
   "source": [
    "### 5.1 Visualize Land Cover from the GLanCE30 Land Cover Time Series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49aed2b-ba7d-4329-875c-91b8d7bc86ed",
   "metadata": {},
   "source": [
    "Here, we will make a custom color ramp to display the Land Cover time series with the classes represented as a the following colors. \n",
    "\n",
    "- 1 = Water (Blue)\n",
    "- 2 = Snow (White)\n",
    "- 3 = Developed (Red)\n",
    "- 4 = Barren (Grey)\n",
    "- 5 = Tree Cover (Green)\n",
    "- 6 = Shrub (Brown)\n",
    "- 7 = Herbaceous (Tan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419367ef-b920-4f9c-8bec-cbd7bde50865",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgbs = [(70,107,159),(209,222,248),(171,0,0),(179,172,159),(181,197,143),(204,184,121),(223,223,194)]\n",
    "color_list = ['#{:02x}{:02x}{:02x}'.format(r, g, b) for r, g, b in rgbs]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41273c4e-969b-4307-b966-1a51044cb3f9",
   "metadata": {},
   "source": [
    "Here we will make a visualization of the Land Cover Time Series. Cycle through the time series by using the slider bar in the visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a7fdc1-a44b-40a1-93e0-9b5dafdd4c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "land_cover_img = glance_dataset['LC'].hvplot('x', 'y', groupby='date', dynamic=True, rasterize=True, width=700, height=500, cmap = color_list)\n",
    "land_cover_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0f5dfc-c568-4534-b9da-fad64787158a",
   "metadata": {},
   "source": [
    "### 5.2 Visualize Quantitative Land Cover for the Time Series in Line Chart Format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf951a4-107b-40ec-9fd1-abb7a502636d",
   "metadata": {},
   "source": [
    "In this section we will construct a line chart showing the number of pixels for each Land Cover class by year. To start we will need to filter the glance_dataset xarray LC_TIF coordinate by the appropriate  land cover type and make the others as nodata and assign that to new variable. This will then be constructed as a `pandas` dataframe so we can visualize the land cover types counts in a tabular format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebd0f44-c848-47eb-9c23-0d08872279b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "water_pixels = glance_dataset['LC'].where(glance_dataset['LC'] == 1, np.nan).count(('x', 'y'))\n",
    "ice_snow_pixels = glance_dataset['LC'].where(glance_dataset['LC'] == 2, np.nan).count(('x', 'y'))\n",
    "developed_pixels = glance_dataset['LC'].where(glance_dataset['LC'] == 3, np.nan).count(('x', 'y'))\n",
    "barren_sparsely_vegetated_pixels = glance_dataset['LC'].where(glance_dataset['LC'] == 4, np.nan).count(('x', 'y'))\n",
    "tree_cover_pixels = glance_dataset['LC'].where(glance_dataset['LC'] == 5, np.nan).count(('x', 'y'))\n",
    "shrublands_pixels = glance_dataset['LC'].where(glance_dataset['LC'] == 6, np.nan).count(('x', 'y'))\n",
    "herbaceous_pixels = glance_dataset['LC'].where(glance_dataset['LC'] == 7, np.nan).count(('x', 'y'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b848e69-da24-4bfb-b411-708321be65b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "land_cover_data = {'date':water_pixels['date'].dt.year,'Water':water_pixels, 'Snow_Ice':ice_snow_pixels, 'Developed': developed_pixels, 'Barren': barren_sparsely_vegetated_pixels,\n",
    "       'Tree Cover':tree_cover_pixels, 'Shrublands':shrublands_pixels, 'Herbaceous':herbaceous_pixels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41085a4-4612-4cda-9a13-f24d77baa73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "land_cover_table = pd.DataFrame(land_cover_data)\n",
    "land_cover_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf31e8a-e7f4-4172-a70c-92878a71f574",
   "metadata": {},
   "source": [
    "Now we can take the tabular data and create a line chart showing the counts of each land cover over the time series. We can construct the chart using the same custom color ramp we used for the map visualization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19871475-3f0f-411f-89ea-6519d786e831",
   "metadata": {},
   "outputs": [],
   "source": [
    "chart_colors = {'Water':color_list[0], 'Snow_Ice':color_list[1], 'Developed':color_list[2], 'Barren':color_list[3],\n",
    "                'Tree Cover':color_list[4],'Shrublands':color_list[5],'Herbaceous':color_list[6]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ad1068-680a-442f-8a2a-223bc78bdf62",
   "metadata": {},
   "outputs": [],
   "source": [
    "land_cover_counts = {}\n",
    "for column in land_cover_table.columns:\n",
    "    if column != 'date':\n",
    "        land_cover_counts[column] = hv.Curve((land_cover_table['date'], land_cover_table[column]), label=column).opts(\n",
    "        opts.Curve(color=chart_colors[column]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb43b87d-ec17-4bd3-ac5d-58d9e80c004a",
   "metadata": {},
   "outputs": [],
   "source": [
    "landcover_plot = hv.Overlay(land_cover_counts).opts(\n",
    "    height=300, \n",
    "    width=600,\n",
    "    xlabel='Year', \n",
    "    ylabel='Number of Pixels', \n",
    "    title='Land Cover Class Counts from 2002 - 2019',\n",
    "    legend_position='right',\n",
    "    yformatter='%.0f')\n",
    "landcover_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bddea8-df53-4b18-a9e8-ec1dc4ac1f3f",
   "metadata": {},
   "source": [
    "### 5.3 Visualize Quantitative Previous Class Time Series in Line Chart Format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68fe0be-0474-4282-bebb-57496b7f6c5e",
   "metadata": {},
   "source": [
    "In this section we will construct a line chart showing the number of pixels that changed for each Land Cover class by year. To start we will need to filter the glance_dataset xarray Prev_TIFS coordinate by the appropriate land cover type and make the others as nodata and assign that to new variable. This will then be constructed as a `pandas` dataframe so we can visualize the land cover change class counts in a tabular format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed315e94-c4ba-4248-90b0-8290eb76a00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "water_change_pixels = glance_dataset['PrevClass'].where(glance_dataset['PrevClass'] == 1, np.nan).count(('x', 'y'))\n",
    "ice_snow__change_pixels = glance_dataset['PrevClass'].where(glance_dataset['PrevClass'] == 2, np.nan).count(('x', 'y'))\n",
    "developed_change_pixels = glance_dataset['PrevClass'].where(glance_dataset['PrevClass'] == 3, np.nan).count(('x', 'y'))\n",
    "barren_sparsely_vegetated__change_pixels = glance_dataset['PrevClass'].where(glance_dataset['PrevClass'] == 4, np.nan).count(('x', 'y'))\n",
    "tree_cover_change_pixels = glance_dataset['PrevClass'].where(glance_dataset['PrevClass'] == 5, np.nan).count(('x', 'y'))\n",
    "shrublands_change_pixels = glance_dataset['PrevClass'].where(glance_dataset['PrevClass'] == 6, np.nan).count(('x', 'y'))\n",
    "herbaceous_change_pixels = glance_dataset['PrevClass'].where(glance_dataset['PrevClass'] == 7, np.nan).count(('x', 'y'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a20ed68-8d0e-4330-a5af-be124ffe07b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "land_cover_change_data = {'date':water_change_pixels['date'].dt.year,'Water':water_change_pixels, 'Snow_Ice':ice_snow__change_pixels, \n",
    "                          'Developed': developed_change_pixels, 'Barren': barren_sparsely_vegetated__change_pixels, 'Tree Cover':tree_cover_change_pixels,\n",
    "                          'Shrublands':shrublands_change_pixels, 'Herbaceous':herbaceous_change_pixels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8adc6c4e-dfe2-4667-a398-4b7b5db15feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "land_cover_change_table = pd.DataFrame(land_cover_change_data)\n",
    "land_cover_change_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac30d10-2c0e-43ba-8730-cbc1579f51c1",
   "metadata": {},
   "source": [
    "Now we can take the tabular data and create a line chart showing the counts of each land cover over the time series. The chart can be constructed using the same color ramp created for the chart in section 5.3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafdd5e1-d1fb-4da8-a217-59301acb9982",
   "metadata": {},
   "outputs": [],
   "source": [
    "land_cover_change_counts = {}\n",
    "for column in land_cover_change_table.columns:\n",
    "    if column != 'date':\n",
    "        land_cover_change_counts[column] = hv.Curve((land_cover_change_table['date'], land_cover_change_table[column]), label=column).opts(\n",
    "        opts.Curve(color=chart_colors[column]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f076c471-3130-4a51-9ed1-ce00d3864ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "land_cover_change_plot = hv.Overlay(land_cover_change_counts).opts(\n",
    "    height=300, \n",
    "    width=600,\n",
    "    xlabel='Year', \n",
    "    ylabel='Number of Pixels', \n",
    "    title='Previous Year Land Cover Class Change Counts from 2002 - 2019',\n",
    "    legend_position='right',\n",
    "    yformatter='%.0f')\n",
    "land_cover_change_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628e53f3-2d25-4006-b703-9c700b2af398",
   "metadata": {},
   "source": [
    "### 5.4 Visualize Land Cover from the GLanCE30 Previous Class Time Series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1405b4-0c7f-46d5-8afb-7c8b28510b5a",
   "metadata": {},
   "source": [
    "Here we will make a visualization of the Previous Land Cover Time Series. This will show pixels that have a different land cover class in the current year then it did in the previous year by having a class value other than nodata. Cycle through the time series by using the slider bar in the visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7959468-6af3-4e8f-b57e-8ba49e094bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "land_cover_change_pixels = glance_dataset.where((~np.isnan(glance_dataset['PrevClass'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c64dd37-d45b-4627-bd6f-f15edda5eaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "change_img = land_cover_change_pixels.hvplot('x', 'y', groupby='date', dynamic=True, rasterize=True, width=700, height=500, cmap = color_list)\n",
    "change_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a97bbd-d101-4187-88e7-fdd1f9f7a1d4",
   "metadata": {},
   "source": [
    "### 5.5 Visualize Land Cover from the GLanCE30 Previous Class Time Series with a referance basemap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7600ce3-3c20-4927-ac16-c98e07fa413c",
   "metadata": {},
   "source": [
    "Next we will overlay the areas of change from the time series on a basemap to aid in our spatial awareness. To do this first, we will need to reproject the xarray dataset created by in section 5.4 to a common CRS of WGS84 in order to see the basemap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af52013c-1c49-4270-a794-e4a642258ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "change_reprojected_dataset = land_cover_change_pixels.rio.reproject('epsg:4326')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0256e8ee-69e4-4108-8f7e-e4e4408c2994",
   "metadata": {},
   "outputs": [],
   "source": [
    "change_img_reprojected = change_reprojected_dataset.hvplot('x', 'y', groupby='date', crs = 'epsg:4326', tiles=True, dynamic=True, rasterize=True, width=700, height=500, cmap = color_list)\n",
    "change_img_reprojected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85abf77d-080d-4db4-9118-09c29c2b6336",
   "metadata": {},
   "source": [
    "Success! You have learned how to query for and visualize GLanCE30 Land Cover Data without downloading any of the source data. You can now replace the geojson file, and temporal range in section 2 with your own and re-run the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad72757-7411-48e9-90e7-9ee046492cbb",
   "metadata": {},
   "source": [
    "## Contact Info  \n",
    "\n",
    "Email: LPDAAC@usgs.gov  \n",
    "Voice: +1-866-573-3222  \n",
    "Organization: Land Processes Distributed Active Archive Center (LP DAAC)¹  \n",
    "Website: <https://www.earthdata.nasa.gov/centers/lp-daac>  \n",
    "Date last modified: 06-04-2025  \n",
    "\n",
    "¹Work performed under USGS contract G15PD00467 for NASA contract NNG14HH33I."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lpdaac_vitals",
   "language": "python",
   "name": "lpdaac_vitals"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
